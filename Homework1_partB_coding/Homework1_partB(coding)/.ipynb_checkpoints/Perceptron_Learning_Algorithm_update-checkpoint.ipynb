{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Learning Algorithm\n",
    "\n",
    "The perceptron is a simple supervised machine learning algorithm and one of the earliest neural network architectures. It was introduced by Rosenblatt in the late 1950s. A perceptron represents a binary linear classifier that maps a set of training examples (of $d$ dimensional input vectors) onto binary output values using a $d-1$ dimensional hyperplane. But Today, we will implement **Multi-Classes Perceptron Learning Algorithm** \n",
    "**Given:**\n",
    "* dataset $\\{(x^i, y^i)\\}$, $i \\in (1, M)$\n",
    "* $x^i$ is $d$ dimension vector, $x^i = (x^i_1, \\dots x^i_d)$\n",
    "* $y^i$ is multi-class target varible $y^i \\in \\{0,1,2\\}$\n",
    "\n",
    "A perceptron is trained using gradient descent. The training algorithm has different steps. In the beginning (step 0) the model parameters are initialized. The other steps (see below) are repeated for a specified number of training iterations or until the parameters have converged.\n",
    "\n",
    "**Step0:** Initial the weight vector and bias with zeros     \n",
    "**Step1:** Compute the linear combination of the input features and weight. $y^i_{pred} = argmax_k W_k*x^i + b$    \n",
    "**Step2:** Compute the gradients for parameters $W_k$, $b$. **Derive the parameter update equation Here(5 points)**   \n",
    "\n",
    "##################################     \n",
    "TODO: Derive you answer hear\n",
    "#################################\n",
    "                              \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "X_Shape: (150, 4)\n",
      "y_Shape: (150,)\n",
      "Label Space: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "print(type(X)) #输出X的类型？？？？\n",
    "y = iris.target\n",
    "y = np.array(y)\n",
    "print('X_Shape:', X.shape)\n",
    "print('y_Shape:', y.shape)\n",
    "print('Label Space:', np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_Shape: (105, 4)\n",
      "X_test_Shape: (45, 4)\n",
      "y_train_Shape: (105,)\n",
      "y_test_Shape: (105,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "## split the training set and test set\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, random_state=0)\n",
    "print('X_train_Shape:', X_train.shape)\n",
    "print('X_test_Shape:',  X_test.shape)\n",
    "print('y_train_Shape:', y_train.shape)\n",
    "print('y_test_Shape:',  y_train.shape)\n",
    "\n",
    "print(type(y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClsPLA(object):\n",
    "    \n",
    "    ## We recommend to absorb the bias into weight.  W = [w, b]\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test, lr, num_epoch, weight_dimension, num_cls):\n",
    "        super(MultiClsPLA, self).__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.weight = self.initial_weight(weight_dimension, num_cls)\n",
    "        self.sample_mean = np.mean(self.X_train, 0)\n",
    "        self.sample_std = np.std(self.X_train, 0)\n",
    "        self.num_epoch = num_epoch\n",
    "        self.lr = lr\n",
    "        self.total_acc_train = []\n",
    "        self.total_acc_tst = []\n",
    "          \n",
    "    def initial_weight(self, weight_dimension, num_cls):\n",
    "        weight = None\n",
    "        #########################################\n",
    "        ##  ToDO: Initialize the weight with   ##\n",
    "        ##  samll std and zero mean gaussian   ##\n",
    "        #########################################\n",
    "        mu=0   # init zero mean\n",
    "        sigma=0.01 #init std sigma small\n",
    "        weight=array(np.random.normal(mu,sigma,weight_dimension))\n",
    "        #init weight with normal()\n",
    "        return weight\n",
    "        \n",
    "    def data_preprocessing(self, data):\n",
    "        #####################################\n",
    "        ##  ToDO: Normlize the data        ##\n",
    "        #####################################\n",
    "        norm_data = (data-self.sample_mean)/self.sample_std \n",
    "        \n",
    "        return norm_data\n",
    "    \n",
    "    def train_step(self, X_train, y_train, shuffle_idx):\n",
    "        np.random.shuffle(shuffle_idx)\n",
    "        X_train = X_train[shuffle_idx]\n",
    "        y_train = y_train[shuffle_idx]\n",
    "        train_acc = None\n",
    "        ##############################################\n",
    "        ## TODO: to implement the training process  ##\n",
    "        ## and update the weights                   ##\n",
    "        ##############################################\n",
    "        \n",
    "        y_train_pred=np.pot(weights,X_train.T)\n",
    "        train_acc=np.mean(y_train_pred==y_train)\n",
    "        \n",
    "        if (y_train_pred-y_train) > num_epoch:\n",
    "            weight-=weight*lr\n",
    "        elif (y_train_pred-y_train) < -num_epoch :\n",
    "            weight-=weight*lr\n",
    "        else :\n",
    "            return train_acc\n",
    "        \n",
    "        \n",
    "    def test_step(self, X_test, y_test):\n",
    "        \n",
    "        \n",
    "        X_test = self.data_preprocessing(data=X_test)\n",
    "        num_sample = X_test.shape[0]\n",
    "        test_acc = None\n",
    "        \n",
    "        #########################################\n",
    "        ##  ToDO: Evaluate the test set and    ##\n",
    "        ##  return the test acc                ##\n",
    "        #########################################\n",
    "        y_test_pred=np.pot(weights,X_test.T)\n",
    "        test_acc=np.mean(y_test_pred==y_test)   \n",
    "        return test_acc\n",
    "        \n",
    "    def train(self):\n",
    "           \n",
    "        self.X_train = self.data_preprocessing(data=self.X_train)\n",
    "        num_sample = self.X_train.shape[0]\n",
    "        \n",
    "        ######################################################\n",
    "        ### TODO: In order to absorb the bias into weights ###\n",
    "        ###  we need to modify the input data.             ###\n",
    "        ###  So You need to transform the input data       ###\n",
    "        ######################################################\n",
    "        xones=np.ones(1,X_train.shape[1])\n",
    "        X_train=vstack(X_train,xones)\n",
    "        \n",
    "        shuffle_index = np.array(range(0, num_sample))\n",
    "        for epoch in range(self.num_epoch):\n",
    "            training_acc = self.train_step(X_train=self.X_train, y_train=self.y_train, shuffle_idx=shuffle_index)\n",
    "            tst_acc = self.test_step(X_test=self.X_test,  y_test=self.y_test)\n",
    "            self.total_acc_train.append(training_acc)\n",
    "            self.total_acc_tst.append(tst_acc)\n",
    "            print('epoch:', epoch, 'traing_acc:%.3f'%training_acc, 'tst_acc:%.3f'%tst_acc)\n",
    "    \n",
    "    def vis_acc_curve(self):\n",
    "        train_acc = np.array(self.total_acc_train)\n",
    "        tst_acc = np.array(self.total_acc_tst)\n",
    "        plt.plot(train_acc)\n",
    "        plt.plot(tst_acc)\n",
    "        plt.legend(['train_acc', 'tst_acc'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'weight_dimension' and 'num_cls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5b1de0b88c85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mweight_dimension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mnum_cls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmulti\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiClsPLA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_dimension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mmulti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmulti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvis_acc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'weight_dimension' and 'num_cls'"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "#######################################################\n",
    "### TODO: \n",
    "### 1. You need to import the model and pass some parameters. \n",
    "### 2. Then training the model with some epoches.\n",
    "### 3. Visualize the training acc and test acc verus epoches\n",
    "lr=0.05\n",
    "num_epoch=0.01\n",
    "weight_dimension=X_train.shape[0]\n",
    "num_cls=X_train.shape[1]\n",
    "\n",
    "multi = MultiClsPLA(X_test, y_test, lr, num_epoch, weight_dimension, num_cls)\n",
    "multi.train()\n",
    "multi.vis_acc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
